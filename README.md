# OntoVector Search API

OntoVector Search API is a semantic search service for ontologies based on precomputed vector embeddings of class labels.
It enables fast, multi-source ontology search and alignment, providing endpoints for keyword search, alignment retrieval, and ontology-level metrics.

The system consists of two main parts:
1.  Vectorisation tool (vectorisation/main_vect.py): Extracts labels from ontologies, generates embeddings, and stores metadata.
2.  Semantic Search API (API/search_main.py): Loads the precomputed data and provides REST endpoints for searching and analysis.

## 📂 Project Structure 

```
vectorisation/
 ├── main_vect.py            # Vectorisation script
 ├── requirements.txt        # Dependencies for vectorisation
 ├── bioportal.json          # Example input file with ontology URLs
API/
 ├── search_main.py          # Main FastAPI application
 ├── requirements.txt        # Dependencies for API
 ├── Dockerfile              # Docker build file
 ├── data/                   # Precomputed ontology datasets
 │    ├── <source_name>/
 │    │     ├── vectors.npy
 │    │     ├── labels.json
 │    │     └── metadata.parquet
```
## 1. Vectorisation Process

The vectorisation script prepares the dataset required by the API.

### Input:
A JSON file (e.g., onto.json) containing the ontology URLs to process.
These URLs should point to the downloadable ontology files.
Example structure for a simple source:
```json
{
  [
    "http://purl.obolibrary.org/obo/go.owl",
    "http://purl.obolibrary.org/obo/doid.owl",
    ...
  ]
}
```

 Output:
 1. vectors.npy – NumPy array containing the embeddings of the ontology labels.
 2. labels.json – List of all extracted labels in the same order as in vectors.npy.
 3. metadata.parquet – Table linking each label to its URI and ontology source.

 How it works:
 1. Loads the ontology URLs from the JSON file.
 2. For each ontology: Extracts all class labels (rdfs:label) from OBO or OWL formats and normalises the labels.
 3. Encodes the labels using the all-MiniLM-L6-v2 model from sentence-transformers.
 4. Stores vectors, labels, and metadata in output files.
 5. Logs any inaccessible URLs or parsing errors.

Run vectorisation:
```basch
cd vectorisation
pip install -r requirements.txt
python main_vect.py
```
*The DATA_PATH variable in main_vect.py must point to your ontology URLs JSON.

## ⚙️2. Data Preparation


Before running the API, create a `data/` folder with one subfolder per ontology source.
Each subfolder must contain the following files (generated by the vectorization script):

1. vectors.npy – NumPy array with the label embeddings.
2. labels.json – List of ontology labels corresponding to the vectors.
3. metadata.parquet – Table with label–URI–ontology mappings.

Example:
```
data/
 ├── bioportal/
 │    ├── vectors.npy
 │    ├── labels.json
 │    └── metadata.parquet
 ├── obo_foundry/
 │    ├── vectors.npy
 │    ├── labels.json
 │    └── metadata.parquet
```

## 🚀 Running the API (Docker)

From inside the API/ directory:

Build the image:
```basch
docker build -t ontovector-search-api .
```
Run container:
```basch
docker run -p 8000:8000 ontovector-search-api
```
Once running, the API will be available at:
- http://localhost:8000
  
Interactive Swagger documentation will be available at:
- http://localhost:8000/docs

