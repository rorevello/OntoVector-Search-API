# OntoVector Search API

OntoVector Search API is a semantic search service for ontologies based on precomputed vector embeddings of class labels.
It enables fast, multi-source ontology search and alignment, providing endpoints for keyword search, alignment retrieval, and ontology-level metrics.

The system consists of two main parts:
1.  Vectorisation tool (vectorisation/main_vect.py): Extracts labels from ontologies, generates embeddings, and stores metadata.
2.  Semantic Search API (API/search_main.py): Loads the precomputed data and provides REST endpoints for searching and analysis.

## ğŸ“‚ Project Structure 

```
vectorisation/
 â”œâ”€â”€ main_vect.py            # Vectorisation script
 â”œâ”€â”€ requirements.txt        # Dependencies for vectorisation
 â”œâ”€â”€ bioportal.json          # Example input file with ontology URLs
API/
 â”œâ”€â”€ search_main.py          # Main FastAPI application
 â”œâ”€â”€ requirements.txt        # Dependencies for API
 â”œâ”€â”€ Dockerfile              # Docker build file
 â”œâ”€â”€ data/                   # Precomputed ontology datasets
 â”‚    â”œâ”€â”€ <source_name>/
 â”‚    â”‚     â”œâ”€â”€ vectors.npy
 â”‚    â”‚     â”œâ”€â”€ labels.json
 â”‚    â”‚     â””â”€â”€ metadata.parquet
```
## 1. Vectorisation Process

The vectorisation script prepares the dataset required by the API.

### Input:
A JSON file (e.g., onto.json) containing the ontology URLs to process.
These URLs should point to the downloadable ontology files.
Example structure for a simple source:
```json
{
  [
    "http://purl.obolibrary.org/obo/go.owl",
    "http://purl.obolibrary.org/obo/doid.owl",
    ...
  ]
}
```

 Output:
 1. vectors.npy â€“ NumPy array containing the embeddings of the ontology labels.
 2. labels.json â€“ List of all extracted labels in the same order as in vectors.npy.
 3. metadata.parquet â€“ Table linking each label to its URI and ontology source.

 How it works:
 1. Loads the ontology URLs from the JSON file.
 2. For each ontology: Extracts all class labels (rdfs:label) from OBO or OWL formats and normalises the labels.
 3. Encodes the labels using the all-MiniLM-L6-v2 model from sentence-transformers.
 4. Stores vectors, labels, and metadata in output files.
 5. Logs any inaccessible URLs or parsing errors.

Run vectorisation:
```basch
cd vectorisation
pip install -r requirements.txt
python main_vect.py
```
*The DATA_PATH variable in main_vect.py must point to your ontology URLs JSON.

## âš™ï¸2. Data Preparation


Before running the API, create a `data/` folder with one subfolder per ontology source.
Each subfolder must contain the following files (generated by the vectorization script):

1. vectors.npy â€“ NumPy array with the label embeddings.
2. labels.json â€“ List of ontology labels corresponding to the vectors.
3. metadata.parquet â€“ Table with labelâ€“URIâ€“ontology mappings.

Example:
```
data/
 â”œâ”€â”€ bioportal/
 â”‚    â”œâ”€â”€ vectors.npy
 â”‚    â”œâ”€â”€ labels.json
 â”‚    â””â”€â”€ metadata.parquet
 â”œâ”€â”€ obo_foundry/
 â”‚    â”œâ”€â”€ vectors.npy
 â”‚    â”œâ”€â”€ labels.json
 â”‚    â””â”€â”€ metadata.parquet
```

## ğŸš€ Running the API (Docker)

From inside the API/ directory:

Build the image:
```basch
docker build -t ontovector-search-api .
```
Run container:
```basch
docker run -p 8000:8000 ontovector-search-api
```
Once running, the API will be available at:
- http://localhost:8000
  
Interactive Swagger documentation will be available at:
- http://localhost:8000/docs

